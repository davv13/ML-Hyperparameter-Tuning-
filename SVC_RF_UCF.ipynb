{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "data = pd.read_excel('Titanic_dataset.xls')\n",
    "\n",
    "# Drop irrelevant columns\n",
    "columns_to_drop = ['name', 'ticket', 'cabin', 'boat', 'body', 'home.dest']\n",
    "data = data.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "data['age'].fillna(data['age'].median(), inplace=True)\n",
    "data['fare'].fillna(data['fare'].mean(), inplace=True)\n",
    "data['embarked'].fillna(data['embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "data = pd.get_dummies(data, columns=['sex', 'embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = data.drop('survived', axis=1)\n",
    "y = data['survived']\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter space for SVM and Random Forest\n",
    "svm_param_space = [\n",
    "    {'C': 0.001, 'kernel': 'linear'},\n",
    "    {'C': 0.01, 'kernel': 'linear'},\n",
    "    {'C': 0.1, 'kernel': 'linear'},\n",
    "    {'C': 1, 'kernel': 'linear'},\n",
    "    {'C': 10, 'kernel': 'linear'},\n",
    "    {'C': 100, 'kernel': 'linear'},\n",
    "    {'C': 0.001, 'kernel': 'rbf'},\n",
    "    {'C': 0.01, 'kernel': 'rbf'},\n",
    "    {'C': 0.1, 'kernel': 'rbf'},\n",
    "    {'C': 1, 'kernel': 'rbf'},\n",
    "    {'C': 10, 'kernel': 'rbf'},\n",
    "    {'C': 100, 'kernel': 'rbf'},\n",
    "]\n",
    "\n",
    "rf_param_space = [\n",
    "    {'n_estimators': 50, 'max_depth': 3},\n",
    "    {'n_estimators': 100, 'max_depth': 3},\n",
    "    {'n_estimators': 150, 'max_depth': 3},\n",
    "    {'n_estimators': 50, 'max_depth': 6},\n",
    "    {'n_estimators': 100, 'max_depth': 6},\n",
    "    {'n_estimators': 150, 'max_depth': 6},\n",
    "    {'n_estimators': 50, 'max_depth': 9},\n",
    "    {'n_estimators': 100, 'max_depth': 9},\n",
    "    {'n_estimators': 150, 'max_depth': 9},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_param_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucb_selection(rewards, attempts, t, c):\n",
    "    ucb_values = []\n",
    "    n = len(rewards)\n",
    "\n",
    "    for i in range(n):\n",
    "        if attempts[i] == 0:\n",
    "            # Exploration term when no attempts have been made\n",
    "            ucb_value = float('inf')\n",
    "        else:\n",
    "            exploitation = rewards[i] / attempts[i]\n",
    "            exploration = c * math.sqrt(math.log(t) / attempts[i])\n",
    "            ucb_value = exploitation + exploration\n",
    "\n",
    "        ucb_values.append(ucb_value)\n",
    "\n",
    "    # Select the hyperparameters with the highest UCB value\n",
    "    selected_index = max(range(n), key=lambda i: ucb_values[i])\n",
    "\n",
    "    return selected_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Titanic Dataset\n",
      "\n",
      "UCB Strategy for SVM:\n",
      "Best validation error: 0.5523809523809524\n",
      "Best hyperparameter configuration: {'C': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "rewards_svm = [0] * len(svm_param_space)\n",
    "attempts_svm = [0] * len(svm_param_space)\n",
    "best_config_ucb_svm = None\n",
    "best_error_ucb_svm = float('inf')\n",
    "\n",
    "max_iterations = 12\n",
    "c = 2  # Exploration parameter\n",
    "\n",
    "# Perform cross-validation for evaluation\n",
    "cv = 5  # Number of cross-validation folds\n",
    "\n",
    "for t in range(1, max_iterations + 1):\n",
    "    # UCB Strategy for SVM\n",
    "    config_idx_ucb_svm = ucb_selection(rewards_svm, attempts_svm, t, c)\n",
    "    config_ucb_svm = svm_param_space[config_idx_ucb_svm]\n",
    "    svm_model = SVC(**config_ucb_svm)\n",
    "\n",
    "    # Train the SVM model on the training set\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Perform cross-validation on the validation set\n",
    "    scores_svm = cross_val_score(svm_model, X_val, y_val, cv=cv)\n",
    "    error_ucb_svm = np.mean(scores_svm)\n",
    "\n",
    "    rewards_svm[config_idx_ucb_svm] += error_ucb_svm\n",
    "    attempts_svm[config_idx_ucb_svm] += 1\n",
    "\n",
    "    if error_ucb_svm < best_error_ucb_svm:\n",
    "        best_config_ucb_svm = config_ucb_svm\n",
    "        best_error_ucb_svm = error_ucb_svm\n",
    "\n",
    "print(\"Dataset: Titanic Dataset\")\n",
    "\n",
    "print(\"\\nUCB Strategy for SVM:\")\n",
    "print(\"Best validation error:\", best_error_ucb_svm)\n",
    "print(\"Best hyperparameter configuration:\", best_config_ucb_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Titanic Dataset\n",
      "\n",
      "UCB Strategy for Random Forest:\n",
      "Best validation error: 0.7333333333333333\n",
      "Best hyperparameter configuration: {'n_estimators': 50, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "rewards_rf = [0] * len(rf_param_space)\n",
    "attempts_rf = [0] * len(rf_param_space)\n",
    "best_config_ucb_rf = None\n",
    "best_error_ucb_rf = float('inf')\n",
    "\n",
    "max_iterations = 4\n",
    "c = 2  # Exploration parameter\n",
    "\n",
    "# Perform cross-validation for evaluation\n",
    "cv = 5  # Number of cross-validation folds\n",
    "\n",
    "for t in range(1, max_iterations + 1):\n",
    "    # UCB Strategy for Random Forest\n",
    "    config_idx_ucb_rf = ucb_selection(rewards_rf, attempts_rf, t, c)\n",
    "    config_ucb_rf = rf_param_space[config_idx_ucb_rf]\n",
    "    rf_model = RandomForestClassifier(**config_ucb_rf)\n",
    "\n",
    "    # Train the Random Forest model on the training set\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Perform cross-validation on the validation set\n",
    "    scores_rf = cross_val_score(rf_model, X_val, y_val, cv=cv)\n",
    "    error_ucb_rf = np.mean(scores_rf)\n",
    "\n",
    "    rewards_rf[config_idx_ucb_rf] += error_ucb_rf\n",
    "    attempts_rf[config_idx_ucb_rf] += 1\n",
    "\n",
    "    if error_ucb_rf < best_error_ucb_rf:\n",
    "        best_config_ucb_rf = config_ucb_rf\n",
    "        best_error_ucb_rf = error_ucb_rf\n",
    "\n",
    "print(\"Dataset: Titanic Dataset\")\n",
    "\n",
    "print(\"\\nUCB Strategy for Random Forest:\")\n",
    "print(\"Best validation error:\", best_error_ucb_rf)\n",
    "print(\"Best hyperparameter configuration:\", best_config_ucb_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final SVM model using the best hyperparameters from UCB strategy\n",
    "svm_model.set_params(**best_config_ucb_svm)\n",
    "svm_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Evaluate performance on the test set using the best hyperparameters from UCB strategy\n",
    "test_predictions_svm = svm_model.predict(X_test)\n",
    "test_accuracy_svm = accuracy_score(y_test, test_predictions_svm)\n",
    "test_precision_svm = precision_score(y_test, test_predictions_svm)\n",
    "test_recall_svm = recall_score(y_test, test_predictions_svm)\n",
    "test_f1_svm = f1_score(y_test, test_predictions_svm)\n",
    "test_roc_auc_svm = roc_auc_score(y_test, svm_model.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final Random Forest model using the best hyperparameters from UCB strategy\n",
    "rf_model.set_params(**best_config_ucb_rf)\n",
    "rf_model.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Evaluate performance on the test set using the best hyperparameters from UCB strategy\n",
    "test_predictions_rf = rf_model.predict(X_test)\n",
    "test_accuracy_rf = accuracy_score(y_test, test_predictions_rf)\n",
    "test_precision_rf = precision_score(y_test, test_predictions_rf)\n",
    "test_recall_rf = recall_score(y_test, test_predictions_rf)\n",
    "test_f1_rf = f1_score(y_test, test_predictions_rf)\n",
    "test_roc_auc_rf = roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UCB-selected hyperparameters for SVM:  {'C': 0.001, 'kernel': 'linear'}\n",
      "UCB-selected performance for SVM:\n",
      "  - Accuracy: 0.6145038167938931\n",
      "  - Precision: 0.8695652173913043\n",
      "  - Recall: 0.1694915254237288\n",
      "  - F1-score: 0.28368794326241137\n",
      "  - ROC AUC: 0.8230049435028248\n",
      "\n",
      "UCB-selected hyperparameters for Random Forest:  {'n_estimators': 50, 'max_depth': 6}\n",
      "UCB-selected performance for Random Forest:\n",
      "  - Accuracy: 0.767175572519084\n",
      "  - Precision: 0.8518518518518519\n",
      "  - Recall: 0.5847457627118644\n",
      "  - F1-score: 0.6934673366834171\n",
      "  - ROC AUC: 0.8556967984934086\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUCB-selected hyperparameters for SVM: \", best_config_ucb_svm)\n",
    "print(\"UCB-selected performance for SVM:\")\n",
    "print(f\"  - Accuracy: {test_accuracy_svm}\")\n",
    "print(f\"  - Precision: {test_precision_svm}\")\n",
    "print(f\"  - Recall: {test_recall_svm}\")\n",
    "print(f\"  - F1-score: {test_f1_svm}\")\n",
    "print(f\"  - ROC AUC: {test_roc_auc_svm}\")\n",
    "\n",
    "print(\"\\nUCB-selected hyperparameters for Random Forest: \", best_config_ucb_rf)\n",
    "print(\"UCB-selected performance for Random Forest:\")\n",
    "print(f\"  - Accuracy: {test_accuracy_rf}\")\n",
    "print(f\"  - Precision: {test_precision_rf}\")\n",
    "print(f\"  - Recall: {test_recall_rf}\")\n",
    "print(f\"  - F1-score: {test_f1_rf}\")\n",
    "print(f\"  - ROC AUC: {test_roc_auc_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
